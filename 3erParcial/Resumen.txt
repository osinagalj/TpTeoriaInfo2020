--------------------------- Compresion -----------------------

Objetivo: reducir cantidad de datos para representar la informacion

Sin perdida, mantiene la integridad, aplicable a: texto, bases de datos, codigo, imagenes criticas. tasas moderadas 4:1, acotada por entropia

con perdida, se obtiene una aproximacion a la informacion real, imagenes, video sonido, tasas altas de compresion

tasa: N:1  (La N nos dice cuanta informacion representa cada dato del comprimido, por ej, una imagen comprimida 4:1 nos dice que por cada dato compreso se obtienen 4 datos de la imagen original)

Modelos:
	Estaticos	Modelo fijo, conocido por ambos (ej, a = 00, b = 01, c = 1)

unica pasada por los datos, distribucion fija (No es la compresion ideal), no se transmiten las probabilidades 


	Semi-Estaticos	Modelo fijo a partir de los datos a comprimir (Ej el huffman que hicimos sobre una imagen en base a las frecuencias de cada pixel)

dos pasadas por los datos, distribucion en base a los datos (Compresion mas eficiente), se debe transmitir las probabilidades para armar la tabla y decodificar



	Dinamicos	 Modelo que se va actualizando a medida que el algoritmo se procesa (Ej el arbol de huffman con el Ø)

Unica pasada por los datos, se va ajustando a los datos y no se transmite/almacena, son algoritmos mas complejos, con mayor costo computacional


 -------------------- METODOS DE COMPRESION -----------------------


Huffman dinamico:  (Simetrico)
arbol vacio
nodos con pesos (Suma de los hijos)
hojas con el sibolo y el peso (Frecuencia de aparicion)
nodo especial Ø asociado al punto de insercion
Cumplir propiedad de sibling (de abajo para arriba y de izquiera a derecha debe estar ordenado de manera creciente)

1- Leer simbolo (Hasta terminar el msj)
2- Generar codigo (Si esta transmitir, si no transmitir el codigo... Si no esta dividir Ø en 2, Ø a la izq y el nuevo a la derecha con peso 1)
3- Actualizar el arbol (si el simbolo esta incrementar en uno y calcular nodos padres, si no, añadir de igual manera)
4- Verificar sibling, si no se cumple reestrucutrar intercambiando los dos en conflicto (El de mayor peso y el mas proximo al inicio se intercambia con el de menor peso y mas cercano a la raiz)(Puede ser necesario mas de un llamado)

Codificacion aritmetica: (Simetrico)
Genera un unico numero de alta precision
Distribuye los simbolos en el rango [0:1) segun probabilidades acumuladas

Algoritmo:  
Lim inf = 0.0 ; Lim sup = 1.0

while (S = leer(simbolo) != finalMensaje){
rango = sup - inf
sup = inf + rango*p(acumuladaSuperior - S)
inf = inf + rango*p(acumuladaInferior - S)}
return cualquier numero entre [inf, sup)  inf para que corte por ej

Diccionario: LZ
LZW: (Simetrico ?)
Carga diccionario con las individuales
lee entrada hasta terminar
	Busca frase de mayor coincidencia y codifica el indice
	agrega al diccionario la frase codificada (La mayor que habia y el simbolo nuevo no coincidente)

RLC (Asimetrico o simetrico... dependiendo la imagen)
Reemplaza secuencias de simbolos con el par (Simbolo - apariciones)
se fija el tamaño para la representacion de la cantidad de apariciones (Cuantos bits)
sirve para largas repeticiones de simbolos (Imagenes con fondos uniformes), no conviene para secuencias de pocos simbolos o muy variados
una mejora es poner un flag cuando se utilice este metodo, y utilizarlo cuando cumpla con un numero minimo de repeticiones

En blancos y negros se omite el simbolo y se empieza por el negro, si empieza con blancos -> 0324

Se puede hacer con perdida de informacion al hacer que haya una tolerancia para la diferencia de intensidad de los pixeles consecutivos


JPEG  (Simetrico)
con perdida: 
aprovecha la sensibilidad del ojo humano a las variaciones de brillo frente a las de color
Los cambios de brillo en areas grandes grandes contra cambios bruscos en areas pequeñas (Como los bordes de objetos)

Separacion en bloques (recomendable 8x8)
(Si es rgb transforma a YIQ/YUV... luminancia-crominancia)
Transformacion discreta del coseno (Funcion sin perdida donde genera un bloque nuevo en base a uno dado)
Cuantificacion, parte con perdida donde se divide el bloque por una matriz de cuantificacion quantum
Se codifica estadisticamente por huffman u aritmetica para las secuencias de ceros

Cuantificacion vectorial (Asimetrico, compresion mas costosa (analisis y eso, descompresion solo es aplicar))

Aproximacion a la imagen, calidad dependiente de tamaño del codebook y del umbral de error tolerado

Construir un diccionario de bloques (Codebook)
dividir la imagen por bloques
asignar a cada bloque el mas cercano a esta
calcular el error promedio
Si el error promedio es menor a una tasa que hayas elegido se codifica la lista de indices con el codebook
(Si no, actualizamos el codebook reemplazando cada vector por el promedio de los que se codificaron y repetir)


Fractal (Asimetrica, compresion mas costosa)

Objeto matematico con propiedades de auto-similitud y detalle a toda escala
Para comprimir encontrar transformaciones que la describen
Comprimir en base a esas transformaciones, luego re generar a partir de ellos

Compresion de video MPEG  (Asimetrico)

Codifica la diferencias entre frames sucesivos por compensascion de movimiento estimada (Vectores de movieminto)

Se codifican 3 tipos de frame
Intra-Frame(I)   (Puntos de acceso, se utiliza JPEG)
Inter-Frame(P) causales (Predictiva al frame I o P anterior)
Inter-frame(B) bidireccionales  (predictiva al frame I o P anterior y posterior)

Compresion de sonido MP3 (Con perdida)

correlaciones entre muestras sucesivas de la señal

Codificacion diferencial (Guardar cuanto varia, y no la señal original)
Si el valor de diferencia es mayor al representable se pierde info

Silencion con RLC, un flag, tolerancia, y si es con valor o silencio

---------------------- Redundancias -----------------------

Estadistica (Considerando las frecuencias de aparicion, huffman por ej)

espacial (Correlaciones de elementos, repeticiones)

Psico-visual (Informacion no importante considerando las limitaciones humanas)

temporal (correlacion entre frames consecutivos, video)

------------------------- Distorcion ------------------------------

Error absoluto promedio
Raiz del error cuadratico medio
pico del cociente señal ruido 

(Filminas)

------------------------- Canales ----------------------------

Medio por el cual se transmite la informacion desde la fuente al destino, puede tener distorciones

Se mide la cantidad de informacion que se transmite

P(x,y) = P(x) / P(y/x) = P(y) / P(x/y)  
(Con esta matriz, suma columna te da las marginales de x, suma fila marginal de y)

P(y/x) = P(x,y) / P(x)
(En esta la columna aplico H y obtengo ruido)
P(x/y) = P(x,y) / P(y)
(En estas columnas aplico H y obtengo perdida)

(Para ir de estas a P(x,y) multiplicamos por la del otro lado xd)

                ruido
H(X,Y) = H(x) + H(Y/X)
H(X,Y) = H(Y) + H(X/Y)
                perdida

I = ahorro de preguntas binarias = informacion mutua
I(X,Y) = H(x) + H(y) - H(x,y)

I(X,Y) = H(x) - H(x/y)
I(X,Y) = H(y) - H(y/x)

C = MAX I(X,Y) = capacidad

Canal BSC (Binary Summetric Channel)

P x1 = alfa
P x2 = 1-alfa

P cruce = beta 
P!cruce = 1-beta

P y1 = alfa + beta - 2alfa*beta
P y2 = 1 - alfa - beta + 2alfa*beta

alfa para C = 1/2
reemplazando, beta = funcion, 0 en 1/2   (En un medio no se para donde fue)
			      1 en extremos (Se directamente a donde fue)

